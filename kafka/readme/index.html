<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Kafka concepts summary - Event Driven Architecture</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="../../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Kafka concepts summary";
    var mkdocs_page_input_path = "kafka\\readme.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Event Driven Architecture</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../concepts/">Concepts</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Architecture</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../architecture/">Reference diagrams</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-src/">Event Sources</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-backbone/">Event Backbone</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-action/">Event Actions</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-state/">Event Managed States</a>
                </li>
                <li class="">
                    
    <a class="" href="../arch/">Event Stream - Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event Storming</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../methodology/readme/">Event Storming Workshop</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc/analysis/readme/">Applied to Container Shipment Analysis</a>
                </li>
                <li class="">
                    
    <a class="" href="../../methodology/ddd/">Domain driven design</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event driven patterns</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../evt-microservices/">Microservices</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-microservices/ED-patterns/">Event-driven patterns</a>
                </li>
                <li class="">
                    
    <a class="" href="../kafka-stream/">Event streaming processing</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../rt-analytics/">Real time analytics</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Reference implementations</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc">Container shipment implementation solution</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Product guidances</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../arch/">Kafka architecture</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Kafka concepts summary</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#apache-kafka">Apache Kafka</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#introduction">Introduction</a></li>
        
            <li><a class="toctree-l4" href="#key-concepts">Key concepts</a></li>
        
            <li><a class="toctree-l4" href="#architecture">Architecture</a></li>
        
            <li><a class="toctree-l4" href="#solution-considerations">Solution considerations</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../producers/">Kafka producer</a>
                </li>
                <li class="">
                    
    <a class="" href="../consumers/">Kafka consumer</a>
                </li>
                <li class="">
                    
    <a class="" href="../FAQ/">Kafka FAQ</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/kafka/">Kafka deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/zookeeper/">Zookeeper deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/eventstreams/Install_Ceph_on_ICP/">Ceph deployment on ICP</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/eventstreams/">Event Streams ICP deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../monitoring/">Kafka Monitoring</a>
                </li>
                <li class="">
                    
    <a class="" href="../../serverless/">Serverless</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/postgresql/">Postgresql</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../eda-skill-journey/">Skill Journey</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../compendium/">Compendium</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Event Driven Architecture</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Product guidances &raquo;</li>
        
      
    
    <li>Kafka concepts summary</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/kafka/readme.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="apache-kafka">Apache Kafka</h1>
<p>In this article we are summarizing what Apache <a href="https://Kafka.apache.org/"><strong>Kafka</strong></a> is and group some references and notes we gathered during our different implementations and  <strong>Kafka</strong> deployment within Kubernetes cluster. We are documenting how to deploy Kafka on IBM Cloud Private or deploying <a href="https://developer.ibm.com/messaging/event-streams/">IBM Event Streams product</a>. This content does not replace <a href="https://Kafka.apache.org/intro/">the excellent introduction</a> every developer using Kafka should read.</p>
<p>Update 06/2019 - <em>Author: <a href="https://www.linkedin.com/in/jeromeboyer/">Jerome Boyer</a></em>  </p>
<h2 id="introduction">Introduction</h2>
<p><a href="https://Kafka.apache.org/">Kafka</a> is a distributed real time event streaming platform with the following key capabilities:</p>
<ul>
<li>Publish and subscribe streams of records. Data are stored so consuming applications can pull the information they need, and keep track of what they have seen so far.</li>
<li>It can handle hundred of reads and writes operation per second from many producers and consumers</li>
<li>Atomic broadcast, send a record once, every subscriber gets it once.</li>
<li>Store streams of data records on disk and replicate within the distributed cluster for fault-tolerance. Keep data for a time period before delete.</li>
<li>Can grow elastically and transparently with no downtime</li>
<li>Built on top of the ZooKeeper synchronization service to keep topic, partitions and metadata highly available.</li>
</ul>
<h3 id="use-cases">Use cases</h3>
<p>The typical use cases where <strong>Kafka</strong> helps are:</p>
<ul>
<li>Centralize online data pipeline to decouple applications and microservices</li>
<li>pub/sub messaging</li>
<li>Aggregation of event coming from multiple producers.</li>
<li>Monitor distributed applications to produce centralized feed of operational data.</li>
<li>Logs collector from multiple services</li>
<li>Implement <a href="../../evt-microservices/ED-patterns/">event soucing pattern</a> out of the box, using configuration to keep message for a long time period. Data are replicated between broker within the cluster and cross availability zones if needed. </li>
<li>Manage loosely coupled communication between microservices. (See <a href="https://github.com/ibm-cloud-architecture/refarch-integration/blob/master/docs/service-mesh.md#asynchronous-loosely-coupled-solution-using-events">this note</a> where I present a way to support a service mesh solution using asynchronous event)</li>
</ul>
<h2 id="key-concepts">Key concepts</h2>
<p>The diagram below presents Kafka's key components:  </p>
<p><img alt="" src="../images/kafka-hl-view.png" /></p>
<h3 id="brokers">Brokers</h3>
<ul>
<li><strong>Kafka</strong> runs as a cluster of one or more <strong>broker</strong> servers that can, in theory, span multiple data centers. It is really possible if the latency is very low at the 10ms or better as there are a lot of communication between kafka brokers and kafka and zookeepers.  </li>
<li>The <strong>Kafka</strong> cluster stores streams of records in <strong>topics</strong>. Topic is referenced by producer to send data too, and subscribed by consumers to get data. </li>
</ul>
<p>In the figure above, the <strong>Kafka</strong> brokers are allocated on three servers, with data within the topic are replicated three times. In production, it is recommended to use five nodes to authorise planned failure and un-planned failure. </p>
<h3 id="topics">Topics</h3>
<p>Topics represent end points to put or get records to.</p>
<ul>
<li>Each record consists of a key, a value, and a timestamp.</li>
<li>Producers publish data records to topic and consumers subscribe to topics. When a record is produced without specifying a partition, a partition will be chosen using a hash of the key. If the record did not provide a timestamp, the producer will stamp the record with its current time (creation time or log append time). Producers hold a pool of buffer to keep records not yet transmitted to the server.</li>
<li>Kafka store log data in its <code>log.dir</code> and topic maps to subdirectories in this log directory.</li>
<li><strong>Kafka</strong> uses topics with a pub/sub combined with queue model: it uses the concept of consumer group to divide the processing over a collection of consumer processes, running in parallel, and messages can be broadcasted to multiple groups.</li>
<li>Consumer performs asynchronous pull to the connected broker via the subscription to a topic.</li>
</ul>
<p>The figure below illustrates one topic having multiple partitions, replicated within the broker cluster:<br />
<img alt="" src="../images/kafka-topic-partition.png" />  </p>
<h3 id="partitions">Partitions</h3>
<p>Partitions are used by producers and consumers and data replication. Partitions are basically used to parallelize the event processing when a single server would not be able to process all events, using the broker clustering. So to manage increase in the load of messages Kafka uses partitions.</p>
<p><img alt="" src="../images/topic-part-offset.png" />   </p>
<ul>
<li>Each broker may have zero or more partitions per topic. When creating topic we specify the number of partition to use. Each partition will run on a separate server. If you have 5 brokers you can define topic with 5 partitions.</li>
<li>Kafka tolerates up to N-1 server failure without losing any messages. N is the replication factor for a given parition. </li>
<li>Each partition is a time ordered immutable sequence of records, that are persisted for a long time period. It is a log. Topic is a labelled log.</li>
<li>Consumers see messages in the order they are stored in the log.</li>
<li>Each partition is replicated across a configurable number of servers for fault tolerance. The number of partition will depend on characteristics like the number of consumers, the traffic pattern, etc...</li>
<li>Each partitioned message has a unique sequence id called <strong>offset</strong> ("abcde, ab, a ..." in the figure above are offsets). Those offset ids are defined when events arrived at the broker level, and are local to the partition. They are unmutable. </li>
<li>When a consumer reads a topic, it actually reads data from all the partitions. As a consumer reads data from a partition, it advances its offset. To read an event the consumer needs to use the topic name, the partition number and the last offset to read from. </li>
<li>As brokers are stateless, the consumers are responsible to keep track of the offsets.</li>
<li>Partitions guarantee that data with the same keys will be sent to the same consumer and in order.</li>
<li>Adding more partition, in the limit of number of brokers, improve throughtput.</li>
</ul>
<h3 id="replication">Replication</h3>
<p>Each partition can be replicated accross a number of server. The replication factor is capted by the number of brokers. Partitions have one leader and zero or more followers. The leader manages all the read and write requests for the partition. Leader is also responsible to track the in sync replicas. The followers replicate the leader content. </p>
<p>If a leader fails, followers elect a new one. When a producer sends message, he can control how to get the response from the committed message: wait for all replicas to succeed. Consumers receive only committed messages. </p>
<h3 id="zookeeper">Zookeeper</h3>
<p>Zookeeper is used to persist the component and platform states and it runs in cluster to ensure high availability. One zookeeper server is the leader and other are used in backup. </p>
<ul>
<li>Kafka does not keep state regarding consumers and producers.</li>
<li>Depends on kafka version, offsets are maintained in Zookeeper or in <strong>Kafka</strong>: newer versions use an internal Kafka topic called __consumer_offsets. In any case consumers can read next message (or from a specific offset) correctly even during broker server outrages. </li>
<li>Access Controls are saved in Zookeeper</li>
</ul>
<h3 id="consumer-group">Consumer group</h3>
<p>This is the way to group consumers so the processing of event is parallelized. The number of consumers in a group is the same as the number of partition defined in a topic. We are detailinh consumer group implementation in <a href="../consumers/">this note</a></p>
<h2 id="architecture">Architecture</h2>
<p>See <a href="../arch/">this separate note</a></p>
<h2 id="solution-considerations">Solution considerations</h2>
<p>There are a set of design considerations to assess for each <strong>Kafka</strong> solution:</p>
<h3 id="topics_1">Topics</h3>
<p>Performance is more a function of number of partitions than topics. Expect that each topic has at least one partition. When considering latency you should aim for limiting to hundreds of topic-partition per broker node.</p>
<p>What of the most important question is what topics to use?. What is an event type? Should we use one topic to support multiple event types? 
Let define that an event type is linked to a main business entity like an Order, a ship, a FridgeredContainer. OrderCreated, OrderCancelled, OrderUpdated, OrderClosed are events linked to the states of the Order. The order of those events matter. So the natural approach is to use one topic per data type or schema, specially when using the topic as Event Sourcing where event order is important to build the audit log. You will use a unique partition to support that. The orderID is the partition key and all events related to the order are in the same topic.</p>
<p>The important requirement to consider is the sequencing or event order. When event order is very important then use a unique partition, and use the entity unique identifier as key. Ordering is not preserved across partitions.</p>
<p>When dealing with entity, independent entities may be in separate topics, when strongly related one may stay together.</p>
<p>Other best practices:</p>
<ul>
<li>When event order is important use the same topic and use the entity unique identifier as partition key.</li>
<li>When two entities are related together by containment relationship then they can be in the same topic. </li>
<li>Different entities are separated to different topics.</li>
<li>It is possible to group topics in coarse grained one when we discover that several consumers are listening to the same topics. </li>
<li>Clearly define the partition key as it could be an compound key based on multiple entities.</li>
</ul>
<p>With <strong>Kafka</strong> stream, state store or KTable, you should separate the changelog topic from the others.</p>
<h3 id="producers">Producers</h3>
<p>When developing a record producer you need to assess the following:</p>
<ul>
<li>What is the expected throughput to send events? Event size * average throughput combined with the expected latency help to compute buffer size.</li>
<li>Can the producer batch events together to send them in batch over one send operation?</li>
<li>Is there a risk for loosing communication? Tune the RETRIES_CONFIG and buffer size</li>
<li>Assess <em>once to exactly once</em> delivery requirement. Look at idempotent producer.</li>
</ul>
<p>See <a href="../producers/">implementation considerations discussion</a></p>
<h3 id="consumers">Consumers</h3>
<p>From the consumer point of view a set of items need to be addressed during design phase:</p>
<ul>
<li>Do you need to group consumers for parallel consumption of events?</li>
<li>What is the processing done once the record is processed out of the topic? And how a record is supposed to be consumed?.</li>
<li>How to persist consumer committed position? (the last offset that has been stored securely)</li>
<li>Assess if offsets need to be persisted outside of Kafka?. From version 0.9 offset management is more efficient, and synchronous or asynchronous operations can be done from the consumer code. </li>
<li>Does record time sensitive, and it is possible that consumers fall behind, so when a consumer restarts he can bypass missed records?</li>
<li>Do the consumer needs to perform joins, aggregations between multiple partitions?</li>
</ul>
<p>See <a href="../consumers/">implementation considerations discussion</a></p>
<p>See <a href="../../compendium/">also the compendium note</a> for more readings.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../producers/" class="btn btn-neutral float-right" title="Kafka producer">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../arch/" class="btn btn-neutral" title="Kafka architecture"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/ibm-cloud-architecture/refarch-eda/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../arch/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../producers/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
