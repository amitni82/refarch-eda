<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Kafka Monitoring - Event Driven Architecture</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="../../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Kafka Monitoring";
    var mkdocs_page_input_path = "kafka\\monitoring.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Event Driven Architecture</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../concepts/">Concepts</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Architecture</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../architecture/">Reference diagrams</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-src/">Event Sources</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-backbone/">Event Backbone</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-action/">Event Actions</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-state/">Event Managed States</a>
                </li>
                <li class="">
                    
    <a class="" href="../arch/">Event Stream - Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event Storming</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../methodology/readme/">Event Storming Workshop</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc/analysis/readme/">Applied to Container Shipment Analysis</a>
                </li>
                <li class="">
                    
    <a class="" href="../../methodology/ddd/">Domain driven design</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event driven patterns</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../evt-microservices/">Microservices</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-microservices/ED-patterns/">Event-driven patterns</a>
                </li>
                <li class="">
                    
    <a class="" href="../kafka-stream/">Event streaming processing</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../rt-analytics/">Real time analytics</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Reference implementations</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc">Container shipment implementation solution</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Product guidances</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../arch/">Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="../readme/">Kafka concepts summary</a>
                </li>
                <li class="">
                    
    <a class="" href="../producers/">Kafka producer</a>
                </li>
                <li class="">
                    
    <a class="" href="../consumers/">Kafka consumer</a>
                </li>
                <li class="">
                    
    <a class="" href="../FAQ/">Kafka FAQ</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/kafka/">Kafka deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/zookeeper/">Zookeeper deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/eventstreams/Install_Ceph_on_ICP/">Ceph deployment on ICP</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/eventstreams/">Event Streams ICP deployment</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Kafka Monitoring</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#monitoring-kafka-with-prometheus-and-grafana">Monitoring Kafka with Prometheus and Grafana</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#what-to-monitor">What to monitor</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../../serverless/">Serverless</a>
                </li>
                <li class="">
                    
    <a class="" href="../../deployments/postgresql/">Postgresql</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../eda-skill-journey/">Skill Journey</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../compendium/">Compendium</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Event Driven Architecture</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Product guidances &raquo;</li>
        
      
    
    <li>Kafka Monitoring</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/kafka/monitoring.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="monitoring-kafka-with-prometheus-and-grafana">Monitoring Kafka with Prometheus and Grafana</h1>
<p><em>Author: Ana Giordano - IBM</em></p>
<p>A comprehensive Kafka monitoring plan should collect metrics from the following components:</p>
<ul>
<li>Kafka Broker(s)</li>
<li>Kafka Cluster (which should include ZooKeeper metrics as Kafka relies on it to maintain its state)</li>
<li>Producer(s) / Consumer(s)</li>
</ul>
<p>Kafka Broker, Zookeeper and Java clients (producer/consumer) expose metrics via JMX (Java Management Extensions) and can be configured to report stats back to Prometheus using the <a href="https://github.com/prometheus/jmx_exporter">JMX exporter</a> maintained by Prometheus.  There is also a number of exporters maintained by the community to explore. Some of them can be used in addition to the JMX export. To monitor Kafka, for example, the JMX exporter is often used to provide broker level metrics, while community exporters claim to provide more accurate cluster level metrics (e.g. <a href="https://github.com/danielqsj/kafka_exporter">Kafka exporter</a>, <a href="https://github.com/cloudflare/kafka_zookeeper_exporter">Kafka Zookeeper Exporter by CloudFlare</a>, and others). Alternatively, you can consider <a href="https://prometheus.io/docs/instrumenting/writing_exporters/">writing your own custom exporter</a>.</p>
<h2 id="what-to-monitor">What to monitor</h2>
<p>A long list of metrics is made available by Kafka (<a href="https://kafka.apache.org/documentation/#monitoring">here</a>) and Zookeeper (<a href="https://zookeeper.apache.org/doc/current/zookeeperJMX.html">here</a>). The easiest way to see the available metrics is to fire up <em>jconsole</em> and point it at a running kafka client or Kafka/Prometheus server; this will allow browsing all metrics with JMX. But you are still left to figure out which ones you want to actively monitor and the ones that you want to be actively alerted.</p>
<p>An simple way to get started would be to start with the <a href="https://grafana.com/dashboards">Grafana’s sample dashboards</a> for the Prometheus exporters you chose to use and then modify them as you learn more about the available metrics and/or your environment on ICP. The <a href="https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/">Monitoring Kafka metrics</a> article by <em>DataDog</em> and <a href="https://blog.serverdensity.com/how-to-monitor-kafka/">How to monitor Kafka</a> by <em>Server Density</em> provides  guidance on key Kafka and Prometheus metrics, reasoning to why you should care about them and suggestions on thresholds to trigger alerts. In the next section, we will demonstrate exactly that; we will start with sample dashboards and make few modifications to exemplify how to configure key Kafka metrics to display in the dashboard.</p>
<h3 id="configuring-server-and-agents">Configuring server and agents</h3>
<p>For convenience and easy configuration, we will use Docker images from DockerHub and make few modifications to DockerFiles to include few additional steps to install, configure and start the servers and exporter agents locally.</p>
<h4 id="kafka-and-zookeeper-servers-with-jmx-exporter"><font color=blue>Kafka and Zookeeper servers with JMX Exporter</font></h4>
<p>We will start with the DockerFile of the <a href="https://hub.docker.com/r/spotify/kafka/~/DockerFile/">Spotify kafka image</a> from DockerHub as it includes Zookeeper and Kafka in a single image. The DockerFile was modified as shown below to download, install the Prometheus JMX exporter. The exporter can be configured to scrape and expose mBeans of a JMX target. It runs as a Java Agent, exposing a HTTP server and serving metrics of the JVM. In the DockerFile below, Kafka is started with JMX exporter agent on port 7071 and metrics will be expose in the /metrics endpoint.</p>
<pre class="codehilite"><code>FROM java:openjdk-8-jre

ENV DEBIAN_FRONTEND noninteractive
ENV SCALA_VERSION 2.11
ENV KAFKA_VERSION 0.10.2.2
ENV KAFKA_HOME /opt/kafka_&quot;$SCALA_VERSION&quot;-&quot;$KAFKA_VERSION&quot;

# Install Kafka, Zookeeper and other needed things
RUN apt-get update &amp;&amp; \
    apt-get install -y zookeeper wget supervisor dnsutils vim &amp;&amp; \
    rm -rf /var/lib/apt/lists/* &amp;&amp; \
    apt-get clean &amp;&amp; \
    wget -q http://apache.mirrors.spacedump.net/kafka/&quot;$KAFKA_VERSION&quot;/kafka_&quot;$SCALA_VERSION&quot;-&quot;$KAFKA_VERSION&quot;.tgz -O /tmp/kafka_&quot;$SCALA_VERSION&quot;-&quot;$KAFKA_VERSION&quot;.tgz &amp;&amp; \
    tar xfz /tmp/kafka_&quot;$SCALA_VERSION&quot;-&quot;$KAFKA_VERSION&quot;.tgz -C /opt &amp;&amp; \
    rm /tmp/kafka_&quot;$SCALA_VERSION&quot;-&quot;$KAFKA_VERSION&quot;.tgz

ADD scripts/start-kafka.sh /usr/bin/start-kafka.sh
# ADD scripts/jmx_prometheus_javaagent-0.9.jar &quot;$KAFKA_HOME&quot;/jmx_prometheus_javaagent-0.9.jar
# ADD scripts/kafka-0-8-2.yml &quot;$KAFKA_HOME&quot;/kafka-0-8-2.yml

# Supervisor config
ADD supervisor/kafka.conf supervisor/zookeeper.conf /etc/supervisor/conf.d/

# 2181 is zookeeper, 9092 is kafka
EXPOSE 2181 9092

# **********
# start - modifications to run Prometheus JMX exporter and community Kafka exporter agents
ENV KAFKA_OPTS &quot;-javaagent:$KAFKA_HOME/jmx_prometheus_javaagent-0.9.jar=7071:$KAFKA_HOME/kafka-0-8-2.yml&quot;

RUN wget -q https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.9/jmx_prometheus_javaagent-0.9.jar -O &quot;$KAFKA_HOME&quot;/jmx_prometheus_javaagent-0.9.jar &amp;&amp; \
    wget -q https://raw.githubusercontent.com/prometheus/jmx_exporter/master/example_configs/kafka-0-8-2.yml -O &quot;$KAFKA_HOME&quot;/kafka-0-8-2.yml

EXPOSE 7071
# end - modifications
# **********

CMD [&quot;supervisord&quot;, &quot;-n&quot;]</code></pre>


<p>For your convenience, the modified DockerFile and scripts are available on this <a href="https://github.com/anagiordano/ibm-artifacts">GitHub repository</a>. You can run the following commands to create and run the container locally.</p>
<ol>
<li>download git repo with DockerFile and scripts</li>
</ol>
<pre class="codehilite"><code>mkdir /tmp/monitor
git clone https://github.com/anagiordano/ibm-artifacts.git /tmp/monitor/.</code></pre>


<ol>
<li>Build image from DockerFile</li>
</ol>
<pre class="codehilite"><code>docker build --tag kafka_i /tmp/monitor/kafka/.</code></pre>


<ol>
<li>Create/Run Docker container</li>
</ol>
<pre class="codehilite"><code>docker run -d -p 2181:2181 -p 9092:9092 -p 7071:7071 --env ADVERTISED_PORT=9092 --name kafka_c kafka_i</code></pre>


<ol>
<li>Create kafka topics</li>
</ol>
<pre class="codehilite"><code>docker exec -it kafka_c /bin/bash
cd /opt/kafka*/bin
export KAFKA_OPTS=&quot;&quot;
./kafka-topics.sh --create --zookeeper localhost:2181 --replication-fact 1 --partitions 1 --topic my-topic1
./kafka-topics.sh --create --zookeeper localhost:2181 --replication-fact 1 --partitions 1 --topic my-topic2
./kafka-topics.sh --list --zookeeper localhost:2181</code></pre>


<ol>
<li>(optional) Produce few message into
topics from console and exit container</li>
</ol>
<pre class="codehilite"><code>./kafka-console-producer.sh --broker-list localhost:9092 --topic my-topic1
./kafka-console-producer.sh --broker-list localhost:9092 --topic my-topic2
exit</code></pre>


<p>Lastly you can validate that the /metrics endpoint is returning metrics from Kafka. On a browser, open the http://localhost:7071/metrics URL.</p>
<p><img alt="" src="../images/metrics-endpoint.png" /></p>
<h4 id="prometheus-server-and-scrape-jobs"><font color=blue>Prometheus Server and scrape jobs</font></h4>
<p>Prometheus uses a configuration file in YAML format to define the <a href="https://prometheus.io/docs/concepts/jobs_instances/">scraping jobs and their instances</a>. You can also use the configuration file to define <a href="https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/">recording rules</a> and <a href="https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/">alerting rules</a>:</p>
<ul>
<li>
<p><strong>Recording rules</strong> allow you to precompute frequently needed or computationally expensive expressions and save their result as a new set of time series. Querying the precomputed result will then often be much faster than executing the original expression every time it is needed. This is especially useful for dashboards, which need to query the same expression repeatedly every time they refresh.</p>
</li>
<li>
<p><strong>Alerting rules</strong> allow you to define alert conditions based on Prometheus expression language expressions and to send notifications about firing alerts to an external service. Alerting rules in Prometheus servers send alerts to an Alertmanager. The <a href="https://prometheus.io/docs/alerting/alertmanager/">Alertmanager</a> then manages those alerts, including silencing, inhibition, aggregation and sending out notifications via methods such as email, PagerDuty and others.</p>
</li>
</ul>
<p>Below, we will go thru the steps to stand-up a local Prometheus server as a Docker container and to modify the configuration file to scrape Kafka metrics.</p>
<ol>
<li>Create/run a docker container using Prometheus official image from DockerHub</li>
</ol>
<pre class="codehilite"><code>docker run -d -p 9090:9090 prom/prometheus</code></pre>


<ol>
<li>Obtain the IP address of the Kafka container</li>
</ol>
<pre class="codehilite"><code>docker inspect kafka_c | grep IPAddress</code></pre>


<ol>
<li>Edit the prometheus.yml to add Kafka as a target</li>
</ol>
<pre class="codehilite"><code>docker exec -it prometheus_c \sh
vi /etc/prometheus/prometheus.yml</code></pre>


<ol>
<li>Locate the scrape_configs section in the properties file and add the lines below to define the Kafka job,
where the IP should be the IP of the kafka container</li>
</ol>
<pre class="codehilite"><code>  - job_name: 'kafka'                                                          

    static_configs:                                                            
    - targets: ['172.17.0.4:7071']</code></pre>


<ol>
<li>Reload the configuration file</li>
</ol>
<pre class="codehilite"><code>ps -ef
kill -HUP &lt;prometheus PID&gt;</code></pre>


<ol>
<li>You can now verify that Kafka is listed as a target job in Prometheus. On a Browser, open the http://localhost:9090/targets URL.</li>
</ol>
<p><img alt="" src="../images/prometheus-targets.png" /></p>
<h4 id="grafana-server-and-dashboards"><font color=blue>Grafana Server and dashboards</font></h4>
<p>We will use Grafana for visualization of the metrics scraped by Prometheus for that, we will need to:</p>
<ul>
<li>Stand-up a local Grafana server as a Docker container</li>
<li>Configure Prometheus as a data source in Grafana</li>
<li>Import sample dashboards provided by Grafana and/or community</li>
<li>Modify the sample dashboards as we see fit</li>
</ul>
<p>Let’s get started:</p>
<ol>
<li>Create a docker container using Prometheus official image from DockerHub</li>
</ol>
<pre class="codehilite"><code>docker run -d --name=grafana_c -p 3000:3000 grafana/grafana</code></pre>


<ol>
<li>
<p>On a Browser, open the http://localhost:3000 URL.</p>
</li>
<li>
<p>Login as <strong>admin/admin</strong>. You will be prompted to change the password.</p>
</li>
<li>
<p>Once logged in, Grafana provides visual guidance on what the next steps are: a) Add data sources b) Create first dashboard and others</p>
</li>
</ol>
<p><img alt="" src="../images/grafana-url.png" /></p>
<ol>
<li>
<p>Configure Prometheus as a data source:</p>
</li>
<li>
<p>Enter a <strong>Name</strong> for the data source (e.g. Prometheus)</p>
</li>
<li>Select <strong>Prometheus</strong> as <strong>Type</strong></li>
<li>Enter <strong>http://localhost:9090</strong> for <strong>HTTP URL</strong></li>
<li>In our simple server configuration, select <strong>Browser</strong> for <strong>HTTP Access</strong>  </li>
<li>Click <strong>Save and Test</strong> to validate configuration</li>
</ol>
<p><img alt="" src="../images/grafana-data-source.png" /></p>
<ol>
<li>
<p>Back to Home, click Dashboards -&gt; Manage to import sample dashboards</p>
</li>
<li>
<p>Click the <strong>+Import</strong> button and paste this URL <strong>https://grafana.com/dashboards/721</strong></p>
</li>
<li>Make sure to select <strong>Prometheus</strong> as the data source.</li>
</ol>
<p><strong><em>NOTE:</em></strong> You can also explore other sample dashboard options at https://grafana.com/dashboards. For instance, there is a <a href="https://grafana.com/dashboards/762">Kubernetes Kafka resource metrics</a> sample dashboard that you could use instead as the starting point when configuring Kafka monitoring on ICP.</p>
<p><img alt="" src="../images/grafana-dashboard-import.png" /></p>
<p><img alt="" src="../images/grafana-dashboard-sample.png" /></p>
<p>The six graphs displayed in the dashboard are configured as follows:</p>
<p><strong><em>NOTE:</em></strong> You might want to go back to your Kafka Docker container and push messages into the topics you have created above to see changes to the graph. Or, if you have already pushed messages, you can change the Quick Range from last <em>5 minutes</em> to something else (e.g. <em>last 6 hours</em>) on the top right hand corner of the dashboard.</p>
<table>
<thead>
<tr>
<th align="left">Graph</th>
<th align="left">Formula</th>
<th align="left">Format As</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">CPU Usage</td>
<td align="left">rate(process_cpu_seconds_total{job="kafka"}[1m])</td>
<td align="left">Time Series</td>
</tr>
<tr>
<td align="left">JVM Memory Used</td>
<td align="left">sum without(area)(jvm_memory_bytes_used{job="kafka"})</td>
<td align="left">Time Series</td>
</tr>
<tr>
<td align="left">Time spent in GC</td>
<td align="left">sum without(gc)(rate(jvm_gc_collection_seconds_sum{job="kafka"}[5m]))</td>
<td align="left">Time Series</td>
</tr>
<tr>
<td align="left">Messages In per Topic</td>
<td align="left">sum without(instance)(rate(kafka_server_brokertopicmetrics_messagesin_total{job="kafka",topic!=""}[5m]))</td>
<td align="left">Time Series</td>
</tr>
<tr>
<td align="left">Bytes In per Topic</td>
<td align="left">sum without(instance)(rate(kafka_server_brokertopicmetrics_bytesin_total{job="kafka",topic!=""}[5m]))</td>
<td align="left">Time Series</td>
</tr>
<tr>
<td align="left">Bytes Out per Topic</td>
<td align="left">sum without(instance)(rate(kafka_server_brokertopicmetrics_bytesout_total{job="kafka",topic!=""}[5m]))</td>
<td align="left">Time Series</td>
</tr>
</tbody>
</table>
<p>Prometheus provides a functional expression language that lets the user select and aggregate time series data in real time. Before proceeding review the information on these pages to gain basic understanding of:</p>
<ul>
<li>Prometheus Expression language - http://docs.grafana.org/features/datasources/prometheus/</li>
<li>Grafana Query Editor - http://docs.grafana.org/features/datasources/prometheus/</li>
</ul>
<p>As you make modifications to the dashboard it is also important to understand the data returned by the scrape jobs in the first place. For two of the metrics above, this is what the Kafka JMX exportex returns. You can go to https://localhost:7071/metrics to inspect others returned in /metrics endpoint response:</p>
<ul>
<li>Messages in Per Topic</li>
</ul>
<p><img alt="" src="../images/metrics_messagesin.png" /></p>
<ul>
<li>Time spent in GC</li>
</ul>
<p><img alt="" src="../images/metrics_gc.png" /></p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../serverless/" class="btn btn-neutral float-right" title="Serverless">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../../deployments/eventstreams/" class="btn btn-neutral" title="Event Streams ICP deployment"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/ibm-cloud-architecture/refarch-eda/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../../deployments/eventstreams/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../../serverless/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
