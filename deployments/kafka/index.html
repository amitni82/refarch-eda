<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Kafka deployment - Event Driven Architecture</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="../../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Kafka deployment";
    var mkdocs_page_input_path = "deployments\\kafka\\README.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Event Driven Architecture</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../concepts/">Concepts</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Architecture</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../architecture/">Reference diagrams</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-src/">Event Sources</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-backbone/">Event Backbone</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-action/">Event Actions</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-state/">Event Managed States</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/arch/">Event Stream - Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event Storming</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../methodology/readme/">Event Storming Workshop</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc/analysis/readme/">Applied to Container Shipment Analysis</a>
                </li>
                <li class="">
                    
    <a class="" href="../../methodology/ddd/">Domain driven design</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event driven patterns</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../evt-microservices/">Microservices</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-microservices/ED-patterns/">Event-driven patterns</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/kafka-stream/">Event streaming processing</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../rt-analytics/">Real time analytics</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Reference implementations</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc">Container shipment implementation solution</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Product guidances</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../kafka/arch/">Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/readme/">Kafka concepts summary</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/producers/">Kafka producer</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/consumers/">Kafka consumer</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/FAQ/">Kafka FAQ</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Kafka deployment</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#kafka-deployment">Kafka Deployment</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#development">Development</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../zookeeper/">Zookeeper deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../eventstreams/Install_Ceph_on_ICP/">Ceph deployment on ICP</a>
                </li>
                <li class="">
                    
    <a class="" href="../eventstreams/">Event Streams ICP deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/monitoring/">Kafka Monitoring</a>
                </li>
                <li class="">
                    
    <a class="" href="../../serverless/">Serverless</a>
                </li>
                <li class="">
                    
    <a class="" href="../postgresql/">Postgresql</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../eda-skill-journey/">Skill Journey</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../compendium/">Compendium</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Event Driven Architecture</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Product guidances &raquo;</li>
        
      
    
    <li>Kafka deployment</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/deployments/kafka/README.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="kafka-deployment">Kafka Deployment</h1>
<p>We are proposing three deployment approaches:
* Using IBM Event Streams (See <a href="../eventstreams/">separate note</a>)
* Using Kafka on development environment, mostly developer workstation
* Using IBM Cloud private for production</p>
<p>We are defining two types of manifests, one set for development environment and one for production. The manifests and scripts are under each deployment folders.</p>
<h2 id="development">Development</h2>
<p>For kafka the manifests are in this project under the <code>deployments/kafka/dev</code> folder. We are using the google image: <code>gcr.io/google_samples/k8skafka:v1</code>.</p>
<p>We tested on MacOS with Docker Edge and Kubernetes.</p>
<p>We are also providing scripts to deploy Kafka:</p>
<pre class="codehilite"><code class="language-shell">$ pwd
&gt; deployments/kafka
$ ./deployKafka.sh
$ kubectl get pods -n greencompute
NAME                            READY     STATUS    RESTARTS   AGE
gc-kafka-0                      1/1       Running   0          2m
gc-zookeeper-57dc5679bb-bh29q   1/1       Running   0          10m</code></pre>


<h3 id="verifying-kafka-is-connected-to-zookeeper">Verifying Kafka is connected to zookeeper</h3>
<p>The goal is to connect to the kafka running container and use the scripts inside kafka bin folder:</p>
<pre class="codehilite"><code class="language-shell"># connect to the running container:
$ kubectl exec  -ti gc-kafka-0 /bin/bash -n greencompute
# next is the prompt inside the container:
kafka@gc-kafka-0:/$ cd /opt/kafka/bin
# for example create a topic for testing
kafka@gc-kafka-0:/$./kafka-topics.sh --create  --zookeeper gc-client-zookeeper-svc.greencompute.svc.cluster.local:2181 --replication-factor 1 --partitions 1 --topic text-topic</code></pre>


<p>This previous command create a <code>text-topic</code> and to verify the configured existing topics use the command (inside the container):</p>
<pre class="codehilite"><code class="language-shell">kafka@gc-kafka-0:/$./kafka-topics.sh --list --zookeeper gc-client-zookeeper-svc.greencompute.svc.cluster.local:2181</code></pre>


<p>The URL of the zookeeper matches the hostname defined when deploying zookeeper service (see <a href="../zookeeper/">installing zookeeper note</a> ):</p>
<pre class="codehilite"><code class="language-shell">kubectl describe svc gc-client-zookeeper-svc</code></pre>


<h3 id="verifying-pubsub-works-with-text-messages">Verifying pub/sub works with text messages</h3>
<p>Two scripts exist in the <code>scripts</code> folder in this repository. Those scripts are using <a href="https://docs.confluent.io/current/app-development/kafkacat-usage.html">kafkacat</a> tool from Confluent. You need to add the following in your hostname resolution configuration (DNS or /etc/hosts), matching you IP address of your laptop.</p>
<pre class="codehilite"><code class="language-shell">192.168.1.89 gc-kafka-0.gc-kafka-hl-svc.greencompute.svc.cluster.local</code></pre>


<p>Start the consumer in a terminal window</p>
<pre class="codehilite"><code class="language-shell">./scripts/consumetext.sh</code></pre>


<p>And start the producer in a second terminal:</p>
<pre class="codehilite"><code class="language-shell">./script/producetext.sh</code></pre>


<p>You should see the text:</p>
<pre class="codehilite"><code class="language-shell">try to send some text
to the text-topic
Let see...
% Reached end of topic text-topic [0] at offset 3</code></pre>


<h3 id="run-kafka-in-docker-on-linux">Run Kafka in Docker On Linux</h3>
<p>If you run on a linux operating system, you can use the <a href="https://hub.docker.com/r/spotify/kafka/">Spotify <strong>Kafka</strong> image</a> from dockerhub as it includes Zookeeper and <strong>Kafka</strong> in a single image.</p>
<p>It is started in background (-d), named "<strong>Kafka</strong>" and mounting scripts folder to /scripts:</p>
<pre class="codehilite"><code class="language-shell">docker run -d -p 2181:2181 -p 9092:9092 -v `pwd`:/scripts --env ADVERTISED_HOST=`docker-machine ip \`docker-machine active\`` --name kafka --env ADVERTISED_PORT=9092 spotify/kafka</code></pre>


<p>Then remote connect to the docker container to open a bash shell:</p>
<pre class="codehilite"><code class="language-shell">docker exec  -ti kafka/bin/bash</code></pre>


<p>Create a topic: it uses zookeeper as a backend to persist partition within the topic. In this deployment zookeeper and <strong>Kafka</strong> are running on the localhost inside the container. So port 2181 is the client port for zookeeper.</p>
<pre class="codehilite"><code class="language-shell">cd /opt/kafka/bin
./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic mytopic
./kafka-topics.sh --list --zookeeper localhost:2181</code></pre>


<p>We have done shell scripts for you to do those command and test your local <strong>Kafka</strong>. The scripts are under <code>../scripts/kafka</code></p>
<ul>
<li>createtopic.sh</li>
<li>listtopic.sh</li>
<li>sendText.sh  Send a multiple lines message on mytopic topic- open this one in one terminal.</li>
<li>consumeMessage.sh  Connect to the topic to get messages. and this second in another terminal.</li>
</ul>
<h3 id="considerations">Considerations</h3>
<p>One major requirement to address which impacts kubernetes Kafka Services configuration and Kafka Broker server configuration is to assess remote access need: do we need to have applications not deployed on Kubernetes that should push or consume message to/from topics defined in the Kafka Brokers running in pods. Normally the answer should be yes as all deployments are Hybrid cloud per nature.
As the current client API is doing its own load balancing between brokers we will not be able to use ingress or dynamic node port allocation.</p>
<p>Let explain by starting to review Java code to access brokers. The properties needed to access</p>
<pre class="codehilite"><code class="language-java">public static String BOOTSTRAP_SERVERS = &quot;172.16.40.133:32224,172.16.40.137:32224,172.16.40.135:32224&quot;;
Properties properties = new Properties();
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
kafkaProducer = new KafkaProducer&lt;&gt;(properties);
....</code></pre>


<p>To connect to broker  their addresses and port numbers need to be specified. This information should come from external properties file, but the code above is for illustration. The problem is that once deployed in Kubernetes,  Kafka broker runs as pod so have dynamic port numbers if we expose a service using NodePort, and the IP address may change overtime while pod are scheduled to Node. The list of brokers need to be in the format: <host>:<port>, <host>:<port>,<host>:<port>. So host list, without port number will not work, forbidden the use of virtual host name defined with Ingress manifest and managed by Kubernetes ingress proxy. An external load balancer will not work too.
Here is an example of return message when the broker list is not set right: <code>Connection to node -1 could not be established. Broker may not be available</code>.</p>
<p>There are two options to support remote connection: implement a proxy, deployed inside the Kubernetes cluster, with 3 or 5 hostnames and port to expose the brokers, or use static NodePort. As of now for development we used NodePort:</p>
<pre class="codehilite"><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  labels:
    app: gc-kafka
  name: gc-kafka-svc
spec:
  type: NodePort
  ports:
  - name: kafka-port
    port: 32224
    nodePort: 32224
    targetPort: 32224
  selector:
    app: gc-kafka</code></pre>


<p>So we use a port number for internal and external communication. In statefulset we use a google created tool to start the kafka server and set parameters to override the default the <code>conf/server.properties</code>.</p>
<pre class="codehilite"><code class="language-shell">command:
- &quot;exec kafka-server-start.sh /opt/kafka/config/server.properties --override broker.id=${HOSTNAME##*-} \
  --override listeners=PLAINTEXT://:32224 \</code></pre>


<p>When consumer or producer connect to a broker in the list there are some messages exchanged, like getting the cluster ID and the endpoint to be used which corresponds to a virtual DNS name of the exposed service:
<code>gc-kafka-0.gc-kafka-hl-svc.greencompute.svc.cluster.local</code>:</p>
<pre class="codehilite"><code class="language-shell">INFO  org.apache.kafka.clients.Metadata - Cluster ID: 4qlnD1e-S8ONpOkIOGE8mg
INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=b6e69280-aa7f-47d2-95f5-f69a8f86b967] Discovered group coordinator gc-kafka-0.gc-kafka-hl-svc.greencompute.svc.cluster.local:32224 (id: 2147483647 rack: null)</code></pre>


<p>So the code may not have this entry defined in the DNS. I used /etc/hosts to map it to K8s Proxy IP address. Also the port number return is the one specified in the server configuration, it has to be one Kubernetes and Calico set in the accepted range and exposed on each host of the cluster. With that connection can be established.</p>
<h4 id="verifying-deployment">Verifying deployment</h4>
<p>We can use the tools delivered with Kafka by using the very helpful <code>kubectl exec</code> command.</p>
<ul>
<li>Validate the list of topics from the developer's workstation using the command:</li>
</ul>
<pre class="codehilite"><code class="language-shell">$ kubectl exec -ti gc-Kafka-0 -- bash -c &quot;kafka-topics.sh --list --zookeeper gc-srv-zookeeper-svc.greencompute.svc.cluster.local:2181 &quot;

or
Kafka-topics.sh --describe --topic text-topic --zookeeper gc-srv-zookeeper-svc.greencompute.svc.cluster.local:2181</code></pre>


<ul>
<li>start the consumer from the developer's workstation</li>
</ul>
<pre class="codehilite"><code class="language-shell">kubectl get pods | grep gc-Kafka
kubectl exec gc-Kafka-0 -- bash -c &quot;Kafka-console-consumer.sh --bootstrap-server  localhost:9093 --topic test-topic --from-beginning&quot;</code></pre>


<p>the script <code>deployment/Kafka/consumetext.sh</code> executes those commands. As we run in the Kafka broker the host is localhost and the port number is the headless service one.</p>
<ul>
<li>start a text producer</li>
</ul>
<p>Using the same approach we can use broker tool:</p>
<pre class="codehilite"><code class="language-shell">$ kubectl exec gc-Kafka-0 -- bash -c &quot;/opt/Kafka/bin/Kafka-console-producer.sh --broker-list localhost:9093 --topic test-topic &lt;&lt; EOB
this is a message for you and this one too but this one...
I m not sure
EOB&quot;</code></pre>


<p>Next steps... do pub/sub message using remote IP and port from remote server. The code is in <a href="">this project</a>.</p>
<h3 id="troubleshooting">Troubleshooting</h3>
<p>For ICP troubleshooting see this centralized <a href="https://github.com/ibm-cloud-architecture/refarch-integration/blob/master/docs/icp/troubleshooting.md">note</a></p>
<h4 id="assess-the-list-of-topics">Assess the list of Topics</h4>
<pre class="codehilite"><code class="language-shell"># remote connect to the Kafka pod and open a bash:
kubectl exec -ti Kafka-786975b994-9m8n2 bash
bash-4.4# ./Kafka-topics.sh  --zookeeper 192.168.1.89:30181 --list</code></pre>


<p>Purge a topic with bad message: delete and recreate it</p>
<pre class="codehilite"><code class="language-shell">./Kafka-topics.sh  --zookeeper 192.168.1.89:30181 --delete --topic test-topic
./Kafka-topics.sh  --zookeeper 192.168.1.89:30181 --create --replication-factor 1 --partitions 1 --topic test-topic</code></pre>


<h4 id="timeout-while-sending-message-to-topic">Timeout while sending message to topic</h4>
<p>The error message may look like:</p>
<pre class="codehilite"><code class="language-shell">Error when sending message to topic test-topic with key: null, value: 12 bytes with error: (org.apache.Kafka.clients.producer.internals.ErrorLoggingCallback)
org.apache.Kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.</code></pre>


<p>This can be linked to a lot of different issues, but it is a communication problem. Assess the following:</p>
<ul>
<li>port number exposed match the broker's one.</li>
<li>host name known by the server running the producer or consumer code.</li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../zookeeper/" class="btn btn-neutral float-right" title="Zookeeper deployment">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../../kafka/FAQ/" class="btn btn-neutral" title="Kafka FAQ"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/ibm-cloud-architecture/refarch-eda/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../../kafka/FAQ/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../zookeeper/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
