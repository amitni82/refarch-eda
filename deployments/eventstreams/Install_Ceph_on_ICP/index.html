<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../../img/favicon.ico">
  <title>Ceph deployment on ICP - Event Driven Architecture</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="../../../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Ceph deployment on ICP";
    var mkdocs_page_input_path = "deployments\\eventstreams\\Install_Ceph_on_ICP.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../../.." class="icon icon-home"> Event Driven Architecture</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../../concepts/">Concepts</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Architecture</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../../architecture/">Reference diagrams</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../evt-src/">Event Sources</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../evt-backbone/">Event Backbone</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../evt-action/">Event Actions</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../evt-state/">Event Managed States</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../kafka/arch/">Event Stream - Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event Storming</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../../methodology/readme/">Event Storming Workshop</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc/analysis/readme/">Applied to Container Shipment Analysis</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../methodology/ddd/">Domain driven design</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event driven patterns</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../../evt-microservices/">Microservices</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../evt-microservices/ED-patterns/">Event-driven patterns</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../kafka/kafka-stream/">Event streaming processing</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../../rt-analytics/">Real time analytics</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Reference implementations</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc">Container shipment implementation solution</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Product guidances</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../../kafka/arch/">Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../kafka/readme/">Kafka concepts summary</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../kafka/producers/">Kafka producer</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../kafka/consumers/">Kafka consumer</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../kafka/FAQ/">Kafka FAQ</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/">Kafka deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../../zookeeper/">Zookeeper deployment</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Ceph deployment on ICP</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#install-and-configure-ceph-for-ibm-cloud-private">Install and configure Ceph for IBM Cloud Private</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#environment">Environment</a></li>
        
            <li><a class="toctree-l4" href="#setup">Setup</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#ceph-cluster-management">Ceph Cluster Management</a></li>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../">Event Streams ICP deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../kafka/monitoring/">Kafka Monitoring</a>
                </li>
                <li class="">
                    
    <a class="" href="../../../serverless/">Serverless</a>
                </li>
                <li class="">
                    
    <a class="" href="../../postgresql/">Postgresql</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../../eda-skill-journey/">Skill Journey</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../../compendium/">Compendium</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../..">Event Driven Architecture</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../..">Docs</a> &raquo;</li>
    
      
        
          <li>Product guidances &raquo;</li>
        
      
    
    <li>Ceph deployment on ICP</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/deployments/eventstreams/Install_Ceph_on_ICP.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="install-and-configure-ceph-for-ibm-cloud-private">Install and configure Ceph for IBM Cloud Private</h1>
<p><a href="https://ceph.com/">Ceph</a> is open source software designed to provide highly scalable object, block and file-based storage under a unified system.</p>
<p>Ceph provides a POSIX-compliant network file system (CephFS) that aims for high performance, large data storage, and maximum compatibility with legacy applications.</p>
<p><a href="https://github.com/rook/rook">Rook</a> is an open source orchestrator for distributed storage systems running in cloud native environments.</p>
<p>Rook turns storage software into self-managing, self-scaling, and self-healing storage services. It does this by automating deployment, bootstrapping, configuration, provisioning, scaling, upgrading, migration, disaster recovery, monitoring, and resource management. Rook uses the facilities provided by the underlying cloud-native container management, scheduling and orchestration platform to perform its duties.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Helm chart <em>ibm-rook-rbd-cluster</em> is used for setting up Ceph Cluster in IBM Cloud Private.   </p>
</div>
<h2 id="environment">Environment</h2>
<p>A typical IBM Cloud Private Environment includes Boot node, Master node, Management node, Proxy node and Worker nodes. When the Ceph RBD Cluster is used for providing storage for API Connect, any three worker nodes should be configured to have additional raw disks.</p>
<p>The following set of systems can be used as reference for building <em>development (non-HA) environment</em> that runs IBM API Connect workload on IBM Cloud Private.</p>
<table>
<thead>
<tr>
<th align="center">Node type</th>
<th align="center">Number of nodes</th>
<th align="center">CPU</th>
<th align="center">Memory (GB)</th>
<th align="center">Disk (GB)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Boot (FTP Server)</td>
<td align="center">1</td>
<td align="center">8</td>
<td align="center">32</td>
<td align="center">2048</td>
</tr>
<tr>
<td align="center">Master</td>
<td align="center">1</td>
<td align="center">8</td>
<td align="center">32</td>
<td align="center">300</td>
</tr>
<tr>
<td align="center">Management</td>
<td align="center">1</td>
<td align="center">8</td>
<td align="center">32</td>
<td align="center">300</td>
</tr>
<tr>
<td align="center">Proxy</td>
<td align="center">1</td>
<td align="center">4</td>
<td align="center">16</td>
<td align="center">300</td>
</tr>
<tr>
<td align="center">Worker</td>
<td align="center">3</td>
<td align="center">8</td>
<td align="center">32</td>
<td align="center">300+500(disk2)</td>
</tr>
<tr>
<td align="center">Total</td>
<td align="center">7</td>
<td align="center">52</td>
<td align="center">208</td>
<td align="center">3848+1500(disk2)</td>
</tr>
</tbody>
</table>
<p>The following set of systems can be used as reference for building <em>production (HA) environment</em> that runs IBM API Connect workload on IBM Cloud Private.</p>
<table>
<thead>
<tr>
<th align="center">Node type</th>
<th align="center">Number of nodes</th>
<th align="center">CPU</th>
<th align="center">Memory (GB)</th>
<th align="center">Disk (GB)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Boot (FTP Server)</td>
<td align="center">1</td>
<td align="center">8</td>
<td align="center">32</td>
<td align="center">2048</td>
</tr>
<tr>
<td align="center">Master</td>
<td align="center">3</td>
<td align="center">8</td>
<td align="center">32</td>
<td align="center">300</td>
</tr>
<tr>
<td align="center">Management</td>
<td align="center">2</td>
<td align="center">8</td>
<td align="center">32</td>
<td align="center">300</td>
</tr>
<tr>
<td align="center">Proxy</td>
<td align="center">3</td>
<td align="center">4</td>
<td align="center">16</td>
<td align="center">300</td>
</tr>
<tr>
<td align="center">Worker</td>
<td align="center">3</td>
<td align="center">16</td>
<td align="center">64</td>
<td align="center">300+750(disk2)</td>
</tr>
<tr>
<td align="center">Total</td>
<td align="center">12</td>
<td align="center">108</td>
<td align="center">432</td>
<td align="center">5348+2250(disk2)</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Additional worker nodes will be required when there is a a need to run workloads other than IBM API Connect on IBM Cloud Private.</p>
</div>
<h2 id="setup">Setup</h2>
<p>This document covers the setup of <em>Ceph</em> storage using <em>Rook</em>.</p>
<p>The following tasks are performed for setting up the Ceph Cluster. </p>
<ol>
<li><a href="#1-download-the-required-setup-files">Download the required setup files</a></li>
<li><a href="#2-logon-to-ibm-cloud-private-cluster">Logon to IBM Cloud Private Cluster</a></li>
<li><a href="#3-setup-ceph-cluster">Setup Ceph Cluster</a></li>
<li><a href="#4-verify-ceph-cluster">Verify Ceph cluster</a></li>
<li><a href="#5-troubleshooting-ceph-setup">Troubleshooting Ceph setup</a></li>
</ol>
<h3 id="1-download-the-required-setup-files">1. Download the required setup files</h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following files are required for installing <em>ibm-rook-rbd-cluster</em> chart and setting up Ceph cluster</p>
</div>
<ul>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/scripts/icp/login.sh">login.sh</a> - Utility for logging onto IBM Cloud Private</li>
<li><a href="https://raw.githubusercontent.com/IBM/charts/master/repo/stable/ibm-rook-rbd-cluster-0.8.3.tgz">ibm-rook-rbd-cluster-0.8.3.tgz</a> - IBM Chart for Rook RBD Cluster</li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/ceph-values.yaml">ceph-values.yaml</a> - Sample values.yaml for installing Ceph Cluster </li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/rook-ceph-cluster-role-binding.yaml">rook-ceph-cluster-role-binding.yaml</a> - ClusterRoleBinding for the service account rook-ceph-cluster</li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/rook-ceph-operator-values.yaml">rook-ceph-operator-values.yaml</a> - Sample values.yaml for installing rook operator</li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/rook-cluster-role.yaml">rook-cluster-role.yaml</a> - ClusterRole for the resource rook-privileged</li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/rook-pod-security-policy.yaml">rook-pod-security-policy.yaml</a> - Define PodSecurityPolicy rook-privileged</li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/setup.sh">setup.sh</a> - Utility for setting up Ceph Cluster </li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/status.sh">status.sh</a> - Utility for verifying Ceph Cluster </li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/cleanup.sh">cleanup.sh</a> - Utility for cleaning up Ceph Cluster </li>
</ul>
<h3 id="2-logon-to-ibm-cloud-private-cluster">2. Logon to IBM Cloud Private Cluster</h3>
<p>The script <a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/scripts/icp/login.sh">login.sh</a> can be run to login to IBM Cloud Private Cluster. </p>
<p>!! note
    The script should be updated to include the correct value for <em>CLUSTER_NAME</em>.</p>
<p>Sample run of the login script is as follows: </p>
<p><img alt="" src="../images/loginToDefaultNamespace.png" /></p>
<h3 id="3-setup-ceph-cluster">3. Setup Ceph Cluster</h3>
<p><strong>Step #1</strong> Update the <a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/ceph-values.yaml">ceph-values.yaml</a> to match your environment.</p>
<p>The file <em>ceph-values.yaml</em> needs to be updated to list the IP address of the storage node within the IBM Cloud Private cluster. </p>
<pre class="codehilite"><code>...
#
# UPDATE VARIABLES TO MATCH THE ENVIRONMENT
#   
    nodes:
    - name: &quot;X.X.X.X&quot;
      devices:
      - name: &quot;DISK_NAME&quot;
    - name: &quot;Y.Y.Y.Y&quot;
      devices:
      - name: &quot;DISK_NAME&quot;
    - name: &quot;Z.Z.Z.Z&quot;
      devices:
      - name: &quot;DISK_NAME&quot;
...
...</code></pre>


<p><strong>Step #2</strong> Modify and run the setup script to install Rook Operator chart and the IBM Rook RBD Cluster chart</p>
<p>The contents of the script <a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/setup.sh">setup.sh</a> is as follows: </p>
<pre class="codehilite"><code>#
# UPDATE VARIABLES TO MATCH THE ENVIRONMENT
#

# Define the location of images 
IMAGE_DIR=/DIRECTORY_HAVING_IMAGES

...</code></pre>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The script should be updated to include the correct location for <em>IMAGE_DIR</em> that has the location where the chart ibm-rook-rbd-cluster-0.8.3.tgz is downloaded and unzipped. </p>
</div>
<p>The output of Ceph install is listed below for reference: </p>
<ul>
<li><a href="../samples/ceph_install.log">ceph_install.log</a></li>
</ul>
<h3 id="4-verify-ceph-cluster">4. Verify Ceph cluster</h3>
<p>The script <a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/status.sh">status.sh</a> can be run to check if Ceph cluster is working as expected. </p>
<p>The contents of the script <a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/status.sh">status.sh</a> is as follows: </p>
<pre class="codehilite"><code>./deployments/ceph/status.sh </code></pre>


<p>Expected output is listed below. </p>
<p><img alt="" src="../images/cephGetStatus.png" /></p>
<h3 id="5-troubleshooting-ceph-setup">5. Troubleshooting Ceph setup</h3>
<h4 id="51-steps-for-reseting-an-used-disk">5.1 Steps for reseting an used disk</h4>
<p>It is possible that sometimes OSD pods does't start up even though the OSD prepare jobs have completed successfully. 
It could happen when the device you have specified does not have a raw disk and the device name you have listed was used for other storage like GlusterFS cluster.</p>
<p>In such case the following commands can be run to collect the Logical Volume group ID and Physical volume and remove it fully so that the raw disk is made available for the Ceph cluster.</p>
<pre class="codehilite"><code>pvs
pvdisplay
vgremove LOGIOCAL_VOLUME_GROUP_ID -y 
pvremove PHYSICAL_VOLUME</code></pre>


<p>The output of the aforesaid commands is listed below.</p>
<pre class="codehilite"><code>[root@rsun-rhel-glusterfs03 ~]# pvs
  PV         VG                                  Fmt  Attr PSize   PFree  
  /dev/sda2  rhel                                lvm2 a--   39.00g      0 
  /dev/sdb   vg_687894352b254c630b291bf094a8d43d lvm2 a--  499.87g 499.87g
  /dev/sdc   rhel                                lvm2 a--  500.00g      0 
[root@rsun-rhel-glusterfs03 ~]# pvdisplay
  --- Physical volume ---
  PV Name               /dev/sdb
  VG Name               vg_687894352b254c630b291bf094a8d43d
  PV Size               500.00 GiB / not usable 132.00 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              127967
  Free PE               127967
  Allocated PE          0
  PV UUID               v6xOuh-M2ot-oXfl-IWyf-TnYL-nX3a-kzqizN

  --- Physical volume ---
  PV Name               /dev/sda2
  VG Name               rhel
  PV Size               39.00 GiB / not usable 3.00 MiB
  Allocatable           yes (but full)
  PE Size               4.00 MiB
  Total PE              9983
  Free PE               0
  Allocated PE          9983
  PV UUID               tNjUif-RlBT-kdDn-PWwE-LHlq-3w9O-65Hlph

  --- Physical volume ---
  PV Name               /dev/sdc
  VG Name               rhel
  PV Size               500.00 GiB / not usable 4.00 MiB
  Allocatable           yes (but full)
  PE Size               4.00 MiB
  Total PE              127999
  Free PE               0
  Allocated PE          127999
  PV UUID               7CXpz5-95hb-0WAC-3Efe-XrY1-s6E6-dqLasC

[root@rsun-rhel-glusterfs03 ~]# vgremove vg_687894352b254c630b291bf094a8d43d -y 
  Volume group &quot;vg_687894352b254c630b291bf094a8d43d&quot; successfully removed
[root@rsun-rhel-glusterfs03 ~]# pvremove /dev/sdb 
  Labels on physical volume &quot;/dev/sdb&quot; successfully wiped.</code></pre>


<h4 id="52-steps-for-uninstalling-the-rook-ceph-setup">5.2 Steps for uninstalling the rook-ceph setup</h4>
<p><strong>Step #1</strong> The script <a href="https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/ceph/cleanup.sh">cleanup.sh</a> can be run to remove the Ceph setup completely.</p>
<pre class="codehilite"><code>./deployments/ceph/cleanup.sh</code></pre>


<p><strong>Step #2</strong> Remove the contents of the temporary directory used by rook: <em>/var/lib/rook</em></p>
<p>The following command should run on all the worker nodes: </p>
<pre class="codehilite"><code>rm -fr /var/lib/rook</code></pre>


<h1 id="ceph-cluster-management">Ceph Cluster Management</h1>
<p>The following links has additional details on how to diagnose, troubleshoot, monitor and report Ceph cluster storage: </p>
<ul>
<li><a href="https://github.com/rook/rook/tree/master/Documentation">https://github.com/rook/rook/tree/master/Documentation</a></li>
<li><a href="https://github.com/rook/rook/blob/master/Documentation/common-issues.md#troubleshooting-techniques">https://github.com/rook/rook/blob/master/Documentation/common-issues.md#troubleshooting-techniques</a></li>
<li><a href="https://sysdig.com/blog/monitor-ceph-top-5-metrics-watch/">https://sysdig.com/blog/monitor-ceph-top-5-metrics-watch/</a></li>
<li><a href="https://tracker.ceph.com/projects/ceph/wiki/10_Commands_Every_Ceph_Administrator_Should_Know">https://tracker.ceph.com/projects/ceph/wiki/10_Commands_Every_Ceph_Administrator_Should_Know</a></li>
<li><a href="https://sabaini.at/pages/ceph-cheatsheet.html">https://sabaini.at/pages/ceph-cheatsheet.html</a></li>
</ul>
<p>The <em>Ceph Monitor</em> pod can be attached using the following command:</p>
<pre class="codehilite"><code>kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l &quot;app=rook-ceph-mon&quot; -o jsonpath='{.items[0].metadata.name}') bash</code></pre>


<p>After being attached to the <em>Ceph Monitor</em> pod, the following commands can be run which provides status and statistics of the <em>Ceph Cluster</em>.</p>
<pre class="codehilite"><code>ceph health 
ceph status 
ceph df 
ceph osd stat
ceph osd tree
ceph osd df 
ceph osd df tree
ceph osd perf 
ceph osd pool stats
ceph osd status 
ceph osd utilization
ceph auth list 
ceph quorum_status
ceph mon_status
ceph mon dump 
ceph pg dump 
ceph pg stat</code></pre>


<p>The following link has details on how to add and remove Ceph storage: </p>
<ul>
<li><a href="https://github.com/rook/rook/blob/master/design/cluster-update.md">https://github.com/rook/rook/blob/master/design/cluster-update.md</a></li>
</ul>
<p>The following link can be used as reference for backing up and restoring the images stored in the Ceph Pool. </p>
<ul>
<li><a href="https://nicksabine.com/post/ceph-backup/">https://nicksabine.com/post/ceph-backup/</a></li>
</ul>
<p>Related commands are: </p>
<pre class="codehilite"><code>rbd ls -p replicapool
rbd export 
rbd import </code></pre>


<p>The aforesaid commands can be run after being attached to the Ceph Monitor pod. </p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../" class="btn btn-neutral float-right" title="Event Streams ICP deployment">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../../zookeeper/" class="btn btn-neutral" title="Zookeeper deployment"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/ibm-cloud-architecture/refarch-eda/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../../zookeeper/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../../..';</script>
    <script src="../../../js/theme.js" defer></script>
      <script src="../../../search/main.js" defer></script>

</body>
</html>
