<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Event Streams ICP deployment - Event Driven Architecture</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="../../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Event Streams ICP deployment";
    var mkdocs_page_input_path = "deployments\\eventstreams\\README.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Event Driven Architecture</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../concepts/">Concepts</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Architecture</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../architecture/">Reference diagrams</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-src/">Event Sources</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-backbone/">Event Backbone</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-action/">Event Actions</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-state/">Event Managed States</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/arch/">Event Stream - Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event Storming</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../methodology/readme/">Event Storming Workshop</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc/analysis/readme/">Applied to Container Shipment Analysis</a>
                </li>
                <li class="">
                    
    <a class="" href="../../methodology/ddd/">Domain driven design</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Event driven patterns</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../evt-microservices/">Microservices</a>
                </li>
                <li class="">
                    
    <a class="" href="../../evt-microservices/ED-patterns/">Event-driven patterns</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/kafka-stream/">Event streaming processing</a>
                </li>
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/preparation/data-replication/">Data Replication Pattern</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../rt-analytics/">Real time analytics</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Reference implementations</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="https://ibm-cloud-architecture.github.io/refarch-kc">Container shipment implementation solution</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Product guidances</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../kafka/arch/">Kafka architecture</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/readme/">Kafka concepts summary</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/producers/">Kafka producer</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/consumers/">Kafka consumer</a>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/FAQ/">Kafka FAQ</a>
                </li>
                <li class="">
                    
    <a class="" href="../kafka/">Kafka deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="../zookeeper/">Zookeeper deployment</a>
                </li>
                <li class="">
                    
    <a class="" href="Install_Ceph_on_ICP/">Ceph deployment on ICP</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Event Streams ICP deployment</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#install-ibm-event-streams-on-icp">Install IBM Event Streams on ICP</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#configuration-parameters">Configuration Parameters</a></li>
        
            <li><a class="toctree-l4" href="#some-challenges-during-the-installation">Some challenges during the installation</a></li>
        
            <li><a class="toctree-l4" href="#getting-started-application">Getting started application</a></li>
        
            <li><a class="toctree-l4" href="#verifying-icp-kafka-installation">Verifying ICP Kafka installation</a></li>
        
            <li><a class="toctree-l4" href="#further-readings">Further Readings</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../../kafka/monitoring/">Kafka Monitoring</a>
                </li>
                <li class="">
                    
    <a class="" href="../../serverless/">Serverless</a>
                </li>
                <li class="">
                    
    <a class="" href="../postgresql/">Postgresql</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../eda-skill-journey/">Skill Journey</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../compendium/">Compendium</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Event Driven Architecture</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Product guidances &raquo;</li>
        
      
    
    <li>Event Streams ICP deployment</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/deployments/eventstreams/README.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="install-ibm-event-streams-on-icp">Install IBM Event Streams on ICP</h1>
<p><em>(Tested on June 2019 on ibm-eventstreams-dev helm chart 1.2.0 on ICP 3.1.2)</em></p>
<p>You can use the <code>ibm-eventstreams-dev</code> or <code>ibm-eventstreams-prod</code> Helm chart from ICP catalog. The product installation instructions can be found <a href="https://ibm.github.io/event-streams/installing/installing/">here</a>.  </p>
<div class="admonition note">
<p class="admonition-title">Note<p>If you need to upload the tar file for the event streams production (downloaded from IBM passport advantage or other support sites) use the following command:
<code>cloudctl catalog load-archive --archive eventstreams.pak.tar.gz</code></p>
</p>
</div>
<p>As we do not want to rewrite the product documentation, we just want to highlight what was done for our deployment. Our cluster has the following characteristics:</p>
<ul>
<li>Three masters also running ETCD cluster on 3 nodes</li>
<li>Three management nodes</li>
<li>Three proxy</li>
<li>Six worker nodes</li>
</ul>
<p>For worker nodes we need good CPUs and hard disk space. We allocated 12 CPUs - 32 Gb RAM per worker nodes.</p>
<p>You need to decide if persistence should be enabled for ZooKeepers and Kafka brokers. Pre allocate one Persistence Volume per Kafka broker and one per ZooKeeper server.  If you use dynamic persistence volume provisioning, ensure the expected volumes are present at installation time.</p>
<h3 id="configuration-parameters">Configuration Parameters</h3>
<p>The following parameters were changed from default settings:  </p>
<table>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Kafka.autoCreateTopicsEnable</td>
<td align="left">Enable auto-creation of topics</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">persistence.enabled</td>
<td align="left">enable persistent storage for the Kafka brokers</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">persistence.useDynamicProvisioning</td>
<td align="left">dynamically create persistent volume claims</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">zookeeper.persistence.enabled</td>
<td align="left">use persistent storage for the ZooKeeper nodes</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">zookeeper.persistence.useDynamicProvisioning</td>
<td align="left">dynamically create persistent volume claims for the ZooKeeper nodes</td>
<td align="left">true</td>
</tr>
<tr>
<td align="left">proxy.externalAccessEnabled</td>
<td align="left">allow external access to Kafka from outside the Kubernetes cluster</td>
<td align="left">true</td>
</tr>
</tbody>
</table>
<p>The matching <code>server.properties</code> file is under the <code>deployments/eventstreams</code> folder. See parameters description in the <a href="https://kafka.apache.org/documentation/#brokerconfigs">product documentation</a> </p>
<p>You can get the details of the release with: <code>helm list 'green-events-streams' --tls</code> or access helm detail via ICP console: Here is the helm release details:</p>
<p><img alt="" src="images/ies-helm-rel01.png" /></p>
<p>The figure above shows the following elements:
* ConfigMaps for UI, Kafka proxy
* The five deployments for each major components: UI, REST, proxy and access controller.</p>
<p>Next is the job list which shows what was run during installation. The panel lists also the current network policies: </p>
<p><img alt="" src="images/ies-helm-rel02.png" /></p>
<blockquote>
<p>A network policy is a specification of how groups of pods are allowed to communicate with each other and other network endpoints. As soon as there are policies defined, pods will reject connections not allowed by any policies.</p>
</blockquote>
<p>The pods running in the platform. (One pod was a job)</p>
<p><img alt="" src="images/ies-helm-pods.png" />  </p>
<p>As we can see there are 3 kafka brokers, 3 zookeepers, 2 proxies, 2 access controllers. </p>
<p>You can see the pods running on a node using the command: 
<code>kubectl get pods --all-namespaces --field-selector=spec.nodeName=172.16.50.219</code></p>
<p>The figure below is for roles, rolebinding and secret as part of the Role Based Access Control settings.</p>
<p><img alt="" src="images/ies-helm-rel03.png" /></p>
<p>The figure below shows the services for zookeeper, Kafka and Event Stream REST api and user interface:  </p>
<p><img alt="" src="images/ies-helm-serv.png" /></p>
<p>The services expose capabilities to external world via nodePort type:
* The IBM Event Streams admin console is visible at the port 31253 on the k8s proxy IP address: 172.16.50.227
* The REST api port 30121
* stream proxy port bootstrap: 31348, broker 0: 32489...</p>
<p>You get access to the Event Streams admin console by using the IP address of the master  / proxy node and the port number of the service, which you can get using the kubectl get service command like:</p>
<pre class="codehilite"><code>kubectl get svc -n streaming &quot;green-events-streams-ibm-es-ui-svc&quot; -o 'jsonpath={.spec.ports[?(@.name==&quot;admin-ui-https&quot;)].nodePort}'

kubectl cluster-info | grep &quot;catalog&quot; | awk 'match($0, /([0-9]{1,3}\.){3}[0-9]{1,3}/) { print substr( $0, RSTART, RLENGTH )}'</code></pre>


<p>Here is the admin console home page:</p>
<p><img alt="" src="images/event-stream-admin.png" /></p>
<p>To connect an application or tool to this cluster, you will need the address of a bootstrap server, a certificate and an API key. The page to access this information, is on the top right corner: <code>Connect to this cluster</code>:</p>
<p><img alt="" src="images/ies-cluster-connection.png" /></p>
<p>Download certificate and Java truststore files, and the generated API key. A key can apply to all groups or being specific to a group. </p>
<p>In Java to leverage the api key the code needs to set the some properties:</p>
<pre class="codehilite"><code class="language-java">properties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, &quot;SASL_SSL&quot;);
properties.put(SaslConfigs.SASL_MECHANISM, &quot;PLAIN&quot;);
properties.put(SaslConfigs.SASL_JAAS_CONFIG,
        &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;token\&quot; password=\&quot;&quot;
                + env.get(&quot;KAFKA_APIKEY&quot;) + &quot;\&quot;;&quot;);
properties.put(SslConfigs.SSL_PROTOCOL_CONFIG, &quot;TLSv1.2&quot;);
properties.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, &quot;TLSv1.2&quot;);
properties.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, &quot;HTTPS&quot;);</code></pre>


<p>See code example in <a href="https://github.com/ibm-cloud-architecture/refarch-kc-order-ms/blob/a6b6a2d15085029f5d46b9826806e722a8c27bff/order-command-ms/src/main/java/ibm/labs/kc/order/command/kafka/ApplicationConfig.java#L71-L86">ApplicationConfig.java</a>.</p>
<h2 id="some-challenges-during-the-installation">Some challenges during the installation</h2>
<p>As presented in the high availability discussion in <a href="../kafka#high-availability-in-the-context-of-kubernetes-deployment">this note</a>, normally we need 6 worker nodes to avoid allocating zookeeper and kafka servers on the same kubernetes nodes. The community edition installation is permissive on that constraint, so both products could co-exist but in that case, ensure to have enough physical resources. 
We have seen some Kafka brokers that could not be scheduled because some nodes have taints (can't meet the specs for the stateful set) and the remaining worker nodes don't have enough memory.</p>
<h2 id="getting-started-application">Getting started application</h2>
<p>Use the Event Stream Toolbox to download a getting started application we can use to test the deployment and as code base for future Kafka consumer / producer development.</p>
<p><img alt="" src="images/ies-starter-app.png" />  </p>
<p><img alt="" src="images/ies-starter-app2.png" />  </p>
<p>One example of the generated app is in this repository under <code>gettingStarted/EDAIEWStarterApp</code> folder, and a description on how to compile, package and run it: see the ./gettingStarted/EDAIEWStarterApp/README.md.</p>
<p>The application runs in Liberty at the URL: http://localhost:9080/EDAIESStarterApp/ and delivers a simple user interface splitted into two panels: producer and consumer.</p>
<p><img alt="" src="images/ies-start-app-run.png" />  </p>
<p>The figure below illustrates the fact that the connetion to the broker was not working for a short period of time, so the producer has error, but because of the buffering capabilities, it was able to pace and then as soon as the connection was re-established the consumer started to get the messages. No messages were lost!.</p>
<p><img alt="" src="images/ies-start-app-run2.png" /> </p>
<p>We have two solution implementations using Kafka and Event Streams <a href="https://github.com/ibm-cloud-architecture/refarch-asset-analytics">the manufacturing asset analytics</a> and the  most recent <a href="https://github.com/ibm-cloud-architecture/refarch-kc">KC container shipment solution</a>. We recommend using the second implementation.</p>
<h2 id="verifying-icp-kafka-installation">Verifying ICP Kafka installation</h2>
<p>Once connected to the cluster with kubectl, get the list of pods for the namespace you used to install Kafka or IBM Event Streams:</p>
<pre class="codehilite"><code>$ kubectl get pods -n streaming

NAME                                                              READY     STATUS    RESTARTS
green-even-c353-ibm-es-elas-ad8d-0                                1/1       Running   0          3d
green-even-c353-ibm-es-elas-ad8d-1                                1/1       Running   0          3d
green-even-c353-ibm-es-kafka-sts-0                                4/4       Running   2          3d
green-even-c353-ibm-es-kafka-sts-1                                4/4       Running   2          3d
green-even-c353-ibm-es-kafka-sts-2                                4/4       Running   5          3d
green-even-c353-ibm-es-zook-c4c0-0                                1/1       Running   0          3d
green-even-c353-ibm-es-zook-c4c0-1                                1/1       Running   0          3d
green-even-c353-ibm-es-zook-c4c0-2                                1/1       Running   0          3d
green-events-streams-ibm-es-access-controller-deploy-7cbf8jjs9n   2/2       Running   0          3d
green-events-streams-ibm-es-access-controller-deploy-7cbf8st95z   2/2       Running   0          3d
green-events-streams-ibm-es-indexmgr-deploy-6ff759779-c8ddc       1/1       Running   0          3d
green-events-streams-ibm-es-proxy-deploy-777d6cf76c-bxjtq         1/1       Running   0          3d
green-events-streams-ibm-es-proxy-deploy-777d6cf76c-p8rkc         1/1       Running   0          3d
green-events-streams-ibm-es-rest-deploy-547cc6f9b-774xx           3/3       Running   0          3d
green-events-streams-ibm-es-ui-deploy-7f9b9c6c6f-kvvs2            3/3       Running   0          3d</code></pre>


<p>Select the first pod: green-even-c353-ibm-es-kafka-sts-0 , then execute a bash shell so you can access the Kafka tools:</p>
<pre class="codehilite"><code>$ kubectl exec green-even-c353-ibm-es-kafka-sts-0 -itn streaming -- bash
bash-3.4# cd /opt/Kafka/bin</code></pre>


<p>Now you have access to the kafka tools. The most important thing is to get the hostname and port number of the zookeeper server. To do so use the kubectl command:</p>
<pre class="codehilite"><code>$ kubectl describe pods green-even-c353-ibm-es-zook-c4c0-0  --namespace streaming</code></pre>


<p>In the long result get the client port ( ZK_CLIENT_PORT: 2181) information and IP address (IP: 192.168.76.235). Using this information, in the bash shell within the Kafka broker server we can do the following command to get the topics configured.</p>
<pre class="codehilite"><code class="language-shell">$ ./Kafka-topics.sh --list -zookeeper  192.168.76.235:2181
# We can also use the service name of zookeeper and let k8s DNS resolve the IP address
$ ./Kafka-topics.sh --list -zookeeper  green-even-c353-ibm-es-zook-c4c0-0.streaming.svc.cluster.local:2181</code></pre>


<h3 id="using-the-event-stream-cli">Using the Event Stream CLI</h3>
<p>If not done already, you can install the Event Stream CLI on top of IBM cloud CLI by first downloading it from the Event Stream console and then running this command:</p>
<pre class="codehilite"><code>$ cloudctl plugin install ./es-plugin</code></pre>


<p>Here is a simple summary of the possible <code>cloudctl es</code> commands:</p>
<pre class="codehilite"><code class="language-shell"># Connect to the cluster
cloudctl es init

# create a topic  - default is 3 replicas
cloudctl es topic-create streams-plaintext-input
cloudctl es topic-create streams-wordcount-output --replication-factor 1 --partitions 1

# list topics
cloudctl es topics

# delete topic
cloudctl es topic-delete streams-plaintext-input</code></pre>


<h2 id="further-readings">Further Readings</h2>
<ul>
<li><a href="https://www.ibm.com/cloud/event-streams">IBM Event Streams main page</a></li>
<li><a href="https://ibm.github.io/event-streams">IBM Event Streams Product Documentation</a></li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../kafka/monitoring/" class="btn btn-neutral float-right" title="Kafka Monitoring">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="Install_Ceph_on_ICP/" class="btn btn-neutral" title="Ceph deployment on ICP"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/ibm-cloud-architecture/refarch-eda/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="Install_Ceph_on_ICP/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../../kafka/monitoring/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
